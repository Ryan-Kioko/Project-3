{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Here we combine all data gathered to discover the Overall Sentiment**"],"metadata":{"id":"R5HmzgIsNu0V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuHkgX8dNoNx"},"outputs":[],"source":["# Install required libraries if not already installed\n","!pip install wordcloud\n","!pip install googletrans==3.1.0a0  # For translation in word cloud\n","\n","# Import necessary libraries\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab import drive\n","from wordcloud import WordCloud\n","from googletrans import Translator, LANGUAGES\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.model_selection import train_test_split\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the path to your files\n","path = \"/content/drive/My Drive/Colab Notebooks/Project3/\""]},{"cell_type":"code","source":["# Define file names (update these to match your actual file names)\n","file_names = {\n","    'audio': path + \"audio_data.csv\",\n","    'web': path + \"web_data.csv\",\n","    'reddit': path + \"reddit_data.csv\"\n","}\n","\n","# Columns to keep and standardize across sources\n","columns_to_keep = ['league_name', 'comment', 'sentiment_label', 'sentiment_score']\n","\n","# Dictionary to store dataframes\n","dfs = {}\n","\n","# Read and filter each CSV, adding source identifier\n","for source, file_path in file_names.items():\n","    try:\n","        df = pd.read_csv(file_path)\n","        # Check if required columns exist\n","        missing_cols = [col for col in columns_to_keep if col not in df.columns]\n","        if missing_cols:\n","            print(f\"Warning: {source} data missing columns: {missing_cols}\")\n","        # Filter to keep only specified columns that exist and create a copy\n","        available_cols = [col for col in columns_to_keep if col in df.columns]\n","        df_filtered = df[available_cols].copy()\n","        # Add source column\n","        df_filtered.loc[:, 'source'] = source.capitalize()  # e.g., \"Audio\", \"Web\", \"Reddit\"\n","        dfs[source] = df_filtered\n","    except FileNotFoundError:\n","        print(f\"Error: File not found - {file_path}\")\n","    except Exception as e:\n","        print(f\"Error loading {source} data: {str(e)}\")\n","\n","# Combine available dataframes and transform sentiment scores\n","if dfs:\n","    combined_df = pd.concat(dfs.values(), ignore_index=True)\n","    # Ensure sentiment_score is numeric\n","    combined_df['sentiment_score'] = pd.to_numeric(combined_df['sentiment_score'], errors='coerce')\n","    # Transform 0-1 range to -1-1 range: (score * 2) - 1\n","    combined_df['sentiment_score'] = (combined_df['sentiment_score'] * 2) - 1\n","    # If sentiment_label is \"NEGATIVE\", make the score negative\n","    combined_df.loc[combined_df['sentiment_label'].str.upper() == 'NEGATIVE', 'sentiment_score'] = -abs(combined_df['sentiment_score'])\n","\n","    # Reclassify sentiment labels based on transformed scores to ensure consistency\n","    def classify_sentiment(score):\n","        if pd.isna(score):\n","            return 'NEUTRAL'  # Handle NaN scores\n","        elif score < -0.25:\n","            return 'NEGATIVE'\n","        elif score > 0.25:\n","            return 'POSITIVE'\n","        else:\n","            return 'NEUTRAL'\n","\n","    # Apply classification to update Sentiment labels\n","    combined_df['sentiment_label'] = combined_df['sentiment_score'].apply(classify_sentiment)\n","\n","    # Rename columns for clarity\n","    combined_df = combined_df.rename(columns={\n","        'league_name': 'League',\n","        'comment': 'Sentence',\n","        'sentiment_label': 'Sentiment',\n","        'sentiment_score': 'Score',\n","        'source': 'Source'\n","    })\n","    # Save combined dataframe with all columns\n","    combined_output_path = path + \"finalproject.csv\"\n","    combined_df.to_csv(combined_output_path, index=False)\n","    print(f\"Combined CSV saved as '{combined_output_path}'\")\n","    print(f\"Total rows in combined data: {len(combined_df)}\")\n","    print(\"Columns in combined CSV:\", combined_df.columns.tolist())\n","    # Display first few rows for verification\n","    print(\"\\nSample of combined data:\")\n","    print(combined_df.head())\n","else:\n","    print(\"No dataframes were successfully loaded.\")"],"metadata":{"id":"pxrNu---OADs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if combined_df exists\n","if 'combined_df' in globals():\n","    # Calculate average sentiment score per league\n","    avg_sentiment = combined_df.groupby('League')['Score'].mean().reset_index()\n","\n","    # Add a column to classify sentiment as Negative, Neutral, or Positive\n","    def classify_sentiment(score):\n","        if score < -0.25:\n","            return 'Negative'\n","        elif score > 0.25:\n","            return 'Positive'\n","        else:\n","            return 'Neutral'\n","\n","    avg_sentiment['sentiment_class'] = avg_sentiment['Score'].apply(classify_sentiment)\n","    print(\"\\nAverage Sentiment Score per League (-1 to 1 Scale):\")\n","    print(avg_sentiment)\n","\n","    # Count sentiment labels per league\n","    sentiment_counts = combined_df.groupby(['League', 'Sentiment']).size().unstack(fill_value=0)\n","    print(\"\\nSentiment Label Counts per League:\")\n","    print(sentiment_counts)\n","\n","    # Count total entries per league\n","    total_entries_per_league = combined_df.groupby('League').size().reset_index(name='Total Entries')\n","    print(\"\\nTotal Entries per League:\")\n","    print(total_entries_per_league)\n","\n","    # Check the range of sentiment scores\n","    min_score = combined_df['Score'].min()\n","    max_score = combined_df['Score'].max()\n","    print(f\"\\nSentiment Score Range: {min_score} to {max_score}\")\n","else:\n","    print(\"Error: Combined dataframe not available. Check previous cell for issues.\")"],"metadata":{"id":"HyrvpQAxN_94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if combined_df exists\n","if 'combined_df' in globals():\n","    # Set Seaborn palette\n","    sns.set_palette(\"husl\")\n","\n","    # Create a figure with two subplots\n","    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n","\n","    # Bar plot for average sentiment scores with color coding\n","    palette = sns.color_palette([\"#ff4d4d\", \"#cccccc\", \"#4dff4d\"], n_colors=3)  # Red for neg, gray for neutral, green for pos\n","    sns.barplot(x='League', y='Score', hue='sentiment_class', dodge=False,\n","                palette=palette, data=avg_sentiment, ax=ax1)\n","    ax1.set_title('Average Sentiment Score by League (VAR)', fontsize=14, pad=15)\n","    ax1.set_xlabel('League', fontsize=12)\n","    ax1.set_ylabel('Average Sentiment Score (-1 to 1)', fontsize=12)\n","    ax1.tick_params(axis='x', rotation=45)\n","    ax1.axhline(0, color='gray', linestyle='--', linewidth=1)  # Neutral line at 0\n","    ax1.set_ylim(-1, 1)  # Set y-axis limits to match -1 to 1 range\n","    ax1.legend(title='Sentiment', loc='best')\n","\n","    # Add value labels on top of bars\n","    for i, v in enumerate(avg_sentiment['Score']):\n","        ax1.text(i, v, f'{v:.2f}', ha='center', va='bottom' if v >= 0 else 'top')\n","\n","    # Heatmap for sentiment label counts\n","    sns.heatmap(sentiment_counts, annot=True, fmt='d', cmap='YlOrRd', ax=ax2)\n","    ax2.set_title('Sentiment Label Distribution by League', fontsize=14, pad=15)\n","    ax2.set_xlabel('Sentiment Label', fontsize=12)\n","    ax2.set_ylabel('League', fontsize=12)\n","\n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"Error: Cannot visualize data. Combined dataframe not available.\")"],"metadata":{"id":"QcC11GfDUeeH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the translator\n","translator = Translator()\n","\n","# Check if combined_df exists\n","if 'combined_df' in globals():\n","    # Function to translate text to English\n","    def translate_to_english(text):\n","        try:\n","            # Detect language\n","            detection = translator.detect(text)\n","            if detection.lang != 'en' and detection.confidence > 0.8:  # Only translate if not English and high confidence\n","                translated = translator.translate(text, dest='en')\n","                return translated.text\n","            return text  # Return original if English or low confidence\n","        except Exception as e:\n","            print(f\"Translation error: {e}\")\n","            return text  # Return original on error\n","\n","    # Apply translation to each sentence (formerly 'comment')\n","    translated_sentences = combined_df['Sentence'].dropna().astype(str).apply(translate_to_english)\n","\n","    # Combine all translated sentences into a single string\n","    all_sentences = ' '.join(translated_sentences)\n","\n","    # Generate the word cloud with translated text\n","    wordcloud = WordCloud(width=800, height=400,\n","                          background_color='white',\n","                          min_font_size=10,\n","                          max_words=100).generate(all_sentences)\n","\n","    # Display the word cloud\n","    plt.figure(figsize=(10, 5))\n","    plt.imshow(wordcloud, interpolation='bilinear')\n","    plt.axis('off')\n","    plt.title('Word Cloud of VAR Sentiments', fontsize=14, pad=15)\n","    plt.show()\n","else:\n","    print(\"Error: Cannot generate word cloud. Combined dataframe not available.\")"],"metadata":{"id":"bzpYBgdJghJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a visual pipeline using Matplotlib\n","plt.figure(figsize=(12, 8))\n","\n","# Define pipeline steps (aligned with your 7-step request)\n","steps = [\n","    \"1. Data Ingestion\\n(Audio, Web, Reddit)\",\n","    \"2. Data Preprocessing\\n(Clean & Split)\",\n","    \"3. Language Standardization\\n(Translate to English)\",\n","    \"4. Sentiment Analysis\\n(Predict Labels & Scores)\",\n","    \"5. Result Aggregation\\n(Combine Sources)\",\n","    \"6. Evaluation\\n(Metrics & Validation)\",\n","    \"7. Output & Visualization\\n(CSV, Plots, Word Cloud)\"\n","]\n","\n","# Positions for each step\n","y_positions = [0.9, 0.75, 0.6, 0.45, 0.3, 0.15, 0.0]\n","x_position = 0.5\n","\n","# Draw boxes and text\n","for i, (step, y) in enumerate(zip(steps, y_positions)):\n","    plt.text(x_position, y, step, ha='center', va='center', fontsize=11,\n","             bbox=dict(facecolor='lightblue', edgecolor='black', boxstyle='round,pad=0.5'))\n","\n","# Draw arrows between steps\n","for i in range(len(y_positions) - 1):\n","    plt.arrow(x_position, y_positions[i] - 0.05, 0, -0.08, head_width=0.02, head_length=0.02, fc='black', ec='black')\n","\n","# Customize the plot\n","plt.title('Sentiment Analysis Pipeline for VAR Opinions', fontsize=16, pad=20)\n","plt.xlim(0, 1)\n","plt.ylim(-0.1, 1)\n","plt.axis('off')  # Hide axes\n","plt.show()"],"metadata":{"id":"LQk7hhNKhXX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if combined_df exists\n","if 'combined_df' in globals():\n","    # Drop rows with missing labels or scores\n","    df_eval = combined_df.dropna(subset=['Sentiment', 'Score'])\n","\n","    # Define function to predict labels from sentiment scores (-1 to 1)\n","    def predict_label(score):\n","        if score < -0.1:\n","            return 'NEGATIVE'\n","        elif score > 0.1:\n","            return 'POSITIVE'\n","        else:\n","            return 'NEUTRAL'\n","\n","    # True labels (standardize to uppercase for consistency)\n","    y_true = df_eval['Sentiment'].str.upper()\n","\n","    # Predicted labels from sentiment scores\n","    y_pred = df_eval['Score'].apply(predict_label)\n","\n","    # Calculate basic metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n","    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","\n","    # Print metrics\n","    print(\"Classification Metrics:\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision (weighted): {precision:.4f}\")\n","    print(f\"Recall (weighted): {recall:.4f}\")\n","    print(f\"F1 Score (weighted): {f1:.4f}\")\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(y_true, y_pred, labels=['NEGATIVE', 'NEUTRAL', 'POSITIVE'])\n","    print(\"\\nConfusion Matrix:\")\n","    print(cm)\n","\n","    # Display Confusion Matrix\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['NEGATIVE', 'NEUTRAL', 'POSITIVE'])\n","    disp.plot(cmap='Blues')\n","    plt.title('Confusion Matrix for Sentiment Classification')\n","    plt.show()\n","\n","    # Validation Score (using train-test split)\n","    X = df_eval[['Score']]  # Features (just the score for simplicity)\n","    y = y_true\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Predict on test set\n","    y_test_pred = X_test['Score'].apply(predict_label)\n","\n","    # Validation accuracy\n","    validation_accuracy = accuracy_score(y_test, y_test_pred)\n","    print(f\"\\nValidation Accuracy (20% test split): {validation_accuracy:.4f}\")\n","else:\n","    print(\"Error: Combined dataframe not available. Run previous cells first.\")"],"metadata":{"id":"8k4_b4TYlgs-"},"execution_count":null,"outputs":[]}]}