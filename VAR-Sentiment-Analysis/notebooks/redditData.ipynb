{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"S8SuhJA7ZsBw"},"outputs":[],"source":["# Install and import required libraries\n","!pip install praw transformers langdetect textblob  # Add textblob for polarity\n","import praw\n","import pandas as pd\n","from transformers import pipeline\n","from langdetect import detect  # For language detection\n","from textblob import TextBlob  # For polarity calculation\n","from google.colab import drive\n","import time  # For timestamp filtering"]},{"cell_type":"code","source":["# Mount Google Drive to save files\n","drive.mount('/content/drive')"],"metadata":{"id":"0tCehmfCcrQZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up Reddit API credentials\n","# You need to edit this with your own Reddit API credentials\n","reddit = praw.Reddit(\n","    client_id=\"cGMXlBQnV1N5_EgJxRJnvQ\",        # Replace with your Reddit app's client ID\n","    client_secret=\"itKGNCdex1hbmIzszIPFrt7_Ev9hIQ\",# Replace with your Reddit app's client secret\n","    user_agent=\"VAR_Sentiment_Analysis_v1\"       # Replace with a descriptive user agent, e.g., \"VAR_Sentiment_Analysis_v1\"\n",")\n","# How to get credentials: Go to https://www.reddit.com/prefs/apps, create an app, and copy the details."],"metadata":{"id":"A4YKj6kpc9E_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define subreddits and search terms\n","subreddits = {\n","    \"Premier League\": \"PremierLeague\",\n","    \"La Liga\": \"LaLiga\",\n","    \"Serie A\": \"seriea\",\n","    \"Bundesliga\": \"Bundesliga\"\n","}\n","search_query = \"VAR\"  # Keyword to search for VAR-related posts"],"metadata":{"id":"3wMK9pttGRC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract comments from Reddit posts (limited to 2024 onward)\n","data = {\"League\": [], \"Post Title\": [], \"Comment\": []}  # Dictionary to store data\n","start_2024 = int(time.mktime(time.strptime(\"2024-01-01\", \"%Y-%m-%d\")))  # Unix timestamp for Jan 1, 2024\n","\n","for league, subreddit_name in subreddits.items():\n","    print(f\"Processing {league} (r/{subreddit_name})...\")\n","    subreddit = reddit.subreddit(subreddit_name)\n","    # Search for top posts about VAR within the past year (edit limit to 6–10 posts)\n","    posts = subreddit.search(search_query, time_filter=\"year\", limit=10)  # Initial limit higher to ensure 6–10 after filtering\n","\n","    post_count = 0  # Track posts meeting the 2024 criteria\n","    for post in posts:\n","        if post.created_utc >= start_2024:  # Check if post is from 2024 or later\n","            post.comments.replace_more(limit=0)  # Load all comments\n","            for comment in post.comments.list()[:10]:  # Limit to 10 comments per post (edit as needed)\n","                data[\"League\"].append(league)\n","                data[\"Post Title\"].append(post.title)\n","                data[\"Comment\"].append(comment.body)\n","            print(f\"Extracted comments from: {post.title} (Created: {time.ctime(post.created_utc)})\")\n","            post_count += 1\n","            if post_count >= 8:  # Stop at 8 posts (edit to 6–10 as needed)\n","                break\n","        else:\n","            print(f\"Skipped {post.title} (Created: {time.ctime(post.created_utc)}) - Before 2024\")\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(data)\n","print(f\"Total posts processed: {post_count}\")\n","print(\"Sample extracted data:\")\n","print(df.head())"],"metadata":{"id":"0p8A9G8GG6NW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up sentiment analysis and translation pipelines\n","sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n","# Pre-trained model for POSITIVE, NEUTRAL, NEGATIVE sentiment (trained on Twitter data)\n","\n","# Translation pipeline for Romance languages (Spanish, Italian, etc.) to English\n","translator_romance = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ROMANCE-en\")\n","# Fallback translator for other languages (e.g., German) to English\n","translator_general = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-de-en\")  # German-to-English; edit if needed"],"metadata":{"id":"OiJOxaUlG6GG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect language, translate non-English comments, analyze sentiment (POSITIVE, NEUTRAL, NEGATIVE), and add polarity\n","sentiments = []\n","scores = []\n","translated_comments = []\n","polarities = []  # New list for polarity scores\n","\n","for comment in df[\"Comment\"]:\n","    try:\n","        comment_str = str(comment)  # Ensure comment is a string\n","        lang = detect(comment_str)  # Detect language (returns 'en', 'es', 'de', etc.)\n","\n","        # If comment is not in English, translate it\n","        if lang != \"en\":\n","            # Use Romance translator for Spanish, Italian, etc.\n","            if lang in [\"es\", \"it\", \"fr\", \"pt\", \"ro\"]:\n","                translated = translator_romance(comment_str[:512])[0][\"translation_text\"]  # Truncate to 512 chars\n","            # Use general translator for other languages (e.g., German)\n","            else:\n","                translated = translator_general(comment_str[:512])[0][\"translation_text\"]  # Edit model if needed\n","            text_for_analysis = translated\n","            print(f\"Translated '{comment_str[:50]}...' ({lang}) to '{translated[:50]}...'\")\n","        else:\n","            text_for_analysis = comment_str  # Keep English comments as-is\n","\n","        # Analyze sentiment on translated or original English text\n","        result = sentiment_analyzer(text_for_analysis[:512])[0]  # Truncate to 512 tokens\n","        # Map model labels (LABEL_0 = NEGATIVE, LABEL_1 = NEUTRAL, LABEL_2 = POSITIVE)\n","        label_map = {\"LABEL_0\": \"NEGATIVE\", \"LABEL_1\": \"NEUTRAL\", \"LABEL_2\": \"POSITIVE\"}\n","        sentiment = label_map[result[\"label\"]]\n","        sentiments.append(sentiment)      # POSITIVE, NEUTRAL, or NEGATIVE\n","        scores.append(result[\"score\"])    # Confidence score (0 to 1)\n","        translated_comments.append(text_for_analysis)  # Store the text used for analysis\n","\n","        # Calculate polarity using TextBlob (-1 to +1)\n","        polarity = TextBlob(text_for_analysis).sentiment.polarity\n","        polarities.append(polarity)\n","\n","    except Exception as e:\n","        sentiments.append(\"ERROR\")\n","        scores.append(0.0)\n","        translated_comments.append(comment_str)  # Keep original if translation/analysis fails\n","        polarities.append(0.0)  # Default to 0 for errors\n","        print(f\"Error processing comment: {comment_str[:50]}... | {e}\")\n","\n","# Add results to DataFrame\n","df[\"Translated Comment\"] = translated_comments  # The text actually analyzed (translated or original)\n","df[\"Sentiment\"] = sentiments\n","df[\"Sentiment Score\"] = scores\n","df[\"Polarity\"] = polarities  # New column for polarity (-1 to +1)"],"metadata":{"id":"sWvSq2-rG6DZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install and import visualization libraries\n","!pip install matplotlib seaborn  # Install Matplotlib and Seaborn\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Set Seaborn style for better aesthetics\n","sns.set(style=\"whitegrid\")\n","\n","# Plot 1: Bar plot of sentiment counts per league\n","plt.figure(figsize=(10, 6))\n","sns.countplot(data=df, x=\"League\", hue=\"Sentiment\", palette=\"viridis\")\n","plt.title(\"Sentiment Counts by League (2024)\", fontsize=14)\n","plt.xlabel(\"League\", fontsize=12)\n","plt.ylabel(\"Number of Comments\", fontsize=12)\n","plt.legend(title=\"Sentiment\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n","\n","# Plot 2: Box plot of sentiment scores by sentiment category\n","plt.figure(figsize=(8, 6))\n","sns.boxplot(data=df, x=\"Sentiment\", y=\"Sentiment Score\", palette=\"viridis\")\n","plt.title(\"Sentiment Score Distribution (2024)\", fontsize=14)\n","plt.xlabel(\"Sentiment\", fontsize=12)\n","plt.ylabel(\"Sentiment Score\", fontsize=12)\n","plt.tight_layout()\n","plt.show()\n","\n","# Plot 3: Pie charts for each league (2x2 subplots)\n","fig, axes = plt.subplots(2, 2, figsize=(12, 10))  # 2 rows, 2 columns for 4 leagues\n","fig.suptitle(\"Sentiment Distribution by League (2024)\", fontsize=16)\n","\n","leagues = df[\"League\"].unique()\n","colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Negative (blue), Neutral (orange), Positive (green)\n","\n","for i, league in enumerate(leagues):\n","    league_data = df[df[\"League\"] == league][\"Sentiment\"].value_counts()\n","    sizes = [league_data.get(\"NEGATIVE\", 0), league_data.get(\"NEUTRAL\", 0), league_data.get(\"POSITIVE\", 0)]\n","    labels = [\"Negative\", \"Neutral\", \"Positive\"]\n","    row, col = divmod(i, 2)\n","    axes[row, col].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n","    axes[row, col].set_title(league, fontsize=12)\n","\n","plt.tight_layout(rect=[0, 0, 1, 0.95])\n","plt.show()\n","\n","# Plot 4: Box plot of polarity by league\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(data=df, x=\"League\", y=\"Polarity\", palette=\"viridis\")\n","plt.title(\"Polarity Distribution by League (2024)\", fontsize=14)\n","plt.xlabel(\"League\", fontsize=12)\n","plt.ylabel(\"Polarity (-1 to +1)\", fontsize=12)\n","plt.axhline(0, color='gray', linestyle='--', linewidth=1)  # Add neutral line at 0\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"CVkfx1Q_UNpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save results to CSV\n","output_csv_path = \"/content/drive/My Drive/Colab Notebooks/Project3/var_sentiment_2024.csv\"  # Output path (edit folder if needed)\n","df.to_csv(output_csv_path, index=False)\n","print(f\"Sentiment analysis results saved to {output_csv_path}\")\n","print(\"Sample results:\")\n","print(df.head())"],"metadata":{"id":"piVRM6ctG5_O"},"execution_count":null,"outputs":[]}]}